---
title: "Generative AI Can't Replace Expertise"
subtitle: "It Exposes Its Absence"
author: "Ruth Yankson"
date: "today"
format:
  revealjs:
    theme: sky
    transition: slide
    background-transition: fade
    slide-number: true
    chalkboard: true
    footer: "Generative AI & Data Science Expertise"
    css: styles.css
---


### How Can Gen AI Assist Data Scientists? {background-color="#bbdefb"}

::: {.fragment}
![](img/ds_workflow.png){width="100%" fig-align="center"}
:::

::: {.notes}
I believe that generative AI can’t replace expertise. It exposes its absence. Whether you’re a beginner or expert, how can AI assist you through the data science workflow? During data collection, it could help you generate synthetic data to complement your sparse dataset. Generative AI can also instantly suggest cleaning steps_ and oh, the magic of a beautiful plot created in a matter of seconds. Indeed, it could present possible models for your specific case and even recommend the best one to you. 
:::

---

### [RED FLAGS]{style="color: #ff0000;"} {background-color="#f8d7da"}


::: {.fragment}
![](img/confnot.png){width="40%" fig-align="center"}
:::

::: {.notes}

Yet, when it comes to interpretation, you’d better take the LLM’s results with a grain of salt. Why? It could confidently present narratives with weak evidence and imply causality where only correlation exists. Even at the cleaning step, it could remove meaningful outliers or introduce bias. This bias may also appear in your synthetic data.
:::

---

### A Tale of Two Outputs {background-color="#64b5f6"}

::: {.fragment}
![](img/twotale.png){width="90%" fig-align="center"}
:::

::: {.notes}
A beginner may use Gen AI blindly by following practices because they look right, not due to comprehension. Conversely, an expert would ask probing questions, verify assumptions, and cross-check outcomes with domain knowledge. Perfectly mimicking expertise level, the same LLM gives different results. 
:::

---

### Statistical Evidence {background-color="#1976d2"}

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 5
#| fig-align: center

library(ggplot2)

# Create data
df <- data.frame(
  category = c(
    "Don't Fully Trust\nAI-Generated Code",
    "Always Check Code\nBefore Using",
    "AI Code Appears Correct\nWhen It Contains Errors"
  ),
  percentage = c(96, 48, 61),
  group = c("trust", "check", "errors")
)

# Create bar plot
ggplot(df, aes(x = reorder(category, percentage), y = percentage, fill = group)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = paste0(percentage, "%")), hjust = -0.2, size = 6) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 105), breaks = seq(0, 100, 25)) +
  labs(x = "", y = "Percentage of Developers", title = "Developer Trust and Verification of AI-Generated Code") +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none")
```

::: {.fragment .center .small-text}
*Source: [Techradar](https://www.techradar.com/pro/devs-dont-trust-ai-code-but-many-say-they-still-dont-check-it-anyways?utm_source=chatgpt.com)*
:::

::: {.notes}
Let’s take a look at the statistics. According to Techradar, 96% of developers don’t fully trust AI-Generated Code; 61% believe AI code appears correct when it contains errors, and 48% always check AI code before using it. 
:::

---

### Conclusion {background-color="#0d47a1"}
#### Gen AI is a Mirror of Expertise

::: {.fragment}
![](img/takecharge.png){width="100%" fig-align="center"}
:::

::: {.notes}
So, are you convinced enough to up your game as a data scientist by studying rigorously and critically evaluating AI outputs? Or do you still want to stay complacent and let Gen AI control how you solve problems? Whatever you choose, remember that if Gen AI makes your work better, it’s because you were already good; the opposite is true.
:::

---

::: {.fragment .center}
::: {.r-fit-text}
**Thank you!**
:::

![](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExa3ZmcmI4cTJtcjY0OGMxd25jem03emlldGxtMG91a2Nsa3RxMGtwYSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/imHJKSWL5rt8n0fZO8/giphy.gif)

:::

